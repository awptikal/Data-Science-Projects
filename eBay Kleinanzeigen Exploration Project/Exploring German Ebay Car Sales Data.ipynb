{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<u><h1>Exploring the Ebay-Kleinanzeigen Car Sales Dataset</h1></u>\n",
    "\n",
    "<h2>Introduction</h2>\n",
    "<p>Today, we are exploring a subset (50,000 data points) of the dataset (370,000+ data points) that is the German eBay's classifieds used cars section of the website. The original scrapped data set can be found <a href=\"https://www.kaggle.com/orgesleka/used-cars-database/data\">here</a> and the objective will be cleaning it up and analysing any trends in the used car listings dataset.</p>\n",
    "\n",
    "<h2>Data Dictionary</h2>\n",
    "<p>The following are the columns/variables of the dataset along with some descriptions:</p>\n",
    "<ul>\n",
    "<li><b>dateCrawled</b> : when this ad was first crawled, all field-values are taken from this date</li>\n",
    "<li><b>named</b> : \"name\" of the car</li>\n",
    "<li><b>seller</b> : private or dealer</li>\n",
    "<li><b>offerType</b></li>\n",
    "<li><b>price</b> : the price on the ad to sell the car</li>\n",
    "<li><b>abtest</b></li>\n",
    "<li><b>vehicleType</b></li>\n",
    "<li><b>yearOfRegistration</b> : at which year the car was first registered</li>\n",
    "<li><b>gearbox</b></li>\n",
    "<li><b>powerPS</b> : power of the car in PS</li>\n",
    "<li><b>model</b></li>\n",
    "<li><b>odometer</b> : how many kilometers the car has driven</li>\n",
    "<li><b>monthOfRegistration</b> : at which month the car was first registered</li>\n",
    "<li><b>fuelType</b></li>\n",
    "<li><b>brand</b></li>\n",
    "<li><b>notRepairedDamage</b> : if the car has a damage which is not repaired yet</li>\n",
    "<li><b>dateCreated</b> : the date for which the ad at ebay was created</li>\n",
    "<li><b>nrOfPictures</b> : number of pictures in the ad (unfortunately this field contains everywhere a 0 and is thus useless (bug in crawler!) )</li>\n",
    "<li><b>postalCode</b> </li>\n",
    "<li><b>lastSeenOnline</b> : when the crawler saw this ad last online</li>\n",
    "</ul>\n",
    "<h2>Importing the data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# importing the import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read csv data into pandas dataframe\n",
    "autos = pd.read_csv(\"autos.csv\", encoding = \"Latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Information about the data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           dateCrawled                                               name  \\\n",
      "0  2016-03-26 17:47:46                   Peugeot_807_160_NAVTECH_ON_BOARD   \n",
      "1  2016-04-04 13:38:56         BMW_740i_4_4_Liter_HAMANN_UMBAU_Mega_Optik   \n",
      "2  2016-03-26 18:57:24                         Volkswagen_Golf_1.6_United   \n",
      "3  2016-03-12 16:58:10  Smart_smart_fortwo_coupe_softouch/F1/Klima/Pan...   \n",
      "4  2016-04-01 14:38:50  Ford_Focus_1_6_Benzin_TÜV_neu_ist_sehr_gepfleg...   \n",
      "\n",
      "   seller offerType   price   abtest vehicleType  yearOfRegistration  \\\n",
      "0  privat   Angebot  $5,000  control         bus                2004   \n",
      "1  privat   Angebot  $8,500  control   limousine                1997   \n",
      "2  privat   Angebot  $8,990     test   limousine                2009   \n",
      "3  privat   Angebot  $4,350  control  kleinwagen                2007   \n",
      "4  privat   Angebot  $1,350     test       kombi                2003   \n",
      "\n",
      "     gearbox  powerPS   model   odometer  monthOfRegistration fuelType  \\\n",
      "0    manuell      158  andere  150,000km                    3      lpg   \n",
      "1  automatik      286     7er  150,000km                    6   benzin   \n",
      "2    manuell      102    golf   70,000km                    7   benzin   \n",
      "3  automatik       71  fortwo   70,000km                    6   benzin   \n",
      "4    manuell        0   focus  150,000km                    7   benzin   \n",
      "\n",
      "        brand notRepairedDamage          dateCreated  nrOfPictures  \\\n",
      "0     peugeot              nein  2016-03-26 00:00:00             0   \n",
      "1         bmw              nein  2016-04-04 00:00:00             0   \n",
      "2  volkswagen              nein  2016-03-26 00:00:00             0   \n",
      "3       smart              nein  2016-03-12 00:00:00             0   \n",
      "4        ford              nein  2016-04-01 00:00:00             0   \n",
      "\n",
      "   postalCode             lastSeen  \n",
      "0       79588  2016-04-06 06:45:54  \n",
      "1       71034  2016-04-06 14:45:08  \n",
      "2       35394  2016-04-06 20:15:37  \n",
      "3       33729  2016-03-15 03:16:28  \n",
      "4       39218  2016-04-01 14:38:50   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the first 5 rows of the dataset\n",
    "print(autos.head(5), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> Based on the values in some of the colunms such as 'seller' and 'notRepaiedDamage', we see that the dataset is still in German and may have to be translated for easier analysis. Also, in the 'name' column, we see that some of the names are more than alphanumeric and includes some special accent characters (i.e. Ü) which may also have to be cleaned. Furthermore, the date time and numeric columns look okay except maybe the 'price' and 'odometer' column will have to be cleaned. This means the removal of the '$' sign and the comma in the 'price' column and the removal of the 'km' unit and the comma in the 'odometer' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 20 columns):\n",
      "dateCrawled            50000 non-null object\n",
      "name                   50000 non-null object\n",
      "seller                 50000 non-null object\n",
      "offerType              50000 non-null object\n",
      "price                  50000 non-null object\n",
      "abtest                 50000 non-null object\n",
      "vehicleType            44905 non-null object\n",
      "yearOfRegistration     50000 non-null int64\n",
      "gearbox                47320 non-null object\n",
      "powerPS                50000 non-null int64\n",
      "model                  47242 non-null object\n",
      "odometer               50000 non-null object\n",
      "monthOfRegistration    50000 non-null int64\n",
      "fuelType               45518 non-null object\n",
      "brand                  50000 non-null object\n",
      "notRepairedDamage      40171 non-null object\n",
      "dateCreated            50000 non-null object\n",
      "nrOfPictures           50000 non-null int64\n",
      "postalCode             50000 non-null int64\n",
      "lastSeen               50000 non-null object\n",
      "dtypes: int64(5), object(15)\n",
      "memory usage: 7.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# display info on the column variables\n",
    "print(autos.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> Here, we see that most of the data is of type object (i.e. strings) and we have a few integer variables. But, we see that there is some object columns which are better off as floats or integers and these are the 'price' and 'odometer' columns . Furthermore, most of the columns have exactly 50000 data points, however as we see that there is several that have null data and we have either have to remove or assign values to these rows.\n",
    "\n",
    "Also, the column names will have to be converted to Python's preferred snakecase instead of its current camelcase format (i.e. Camel Case: \"dateCrawled\" -> Snake Case: \"data_crawled\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Wrangling</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dateCrawled', 'name', 'seller', 'offerType', 'price', 'abtest',\n",
      "       'vehicleType', 'yearOfRegistration', 'gearbox', 'powerPS', 'model',\n",
      "       'odometer', 'monthOfRegistration', 'fuelType', 'brand',\n",
      "       'notRepairedDamage', 'dateCreated', 'nrOfPictures', 'postalCode',\n",
      "       'lastSeen'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print existing column names\n",
    "print(autos.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> So, lets rename the 'yearOfRegistration', 'monthOfRegistration', 'notRepairedDamage' and 'dateCreated' to more suitable names whilst still explaining the variables intended use. We can call them 'registration_year', 'registration_month', 'unrepaired_damage' and 'ad_created' respectively. Also, the rest of the column names can keep the same name and will also be converted to snakecase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date_crawled', 'name', 'seller', 'offer_type', 'price', 'abtest',\n",
      "       'vehicle_type', 'registration_year', 'gearbox', 'power_ps', 'model',\n",
      "       'odometer', 'registration_month', 'fuel_type', 'brand',\n",
      "       'unrepaired_damage', 'ad_created', 'nr_of_pictures', 'postal_code',\n",
      "       'last_seen'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# import re package to use regex on the strings\n",
    "import re\n",
    "\n",
    "# function to clean the column names\n",
    "def clean_column(col):\n",
    "    col = re.sub('([A-Z])', r'_\\1', col) # put a underscore before the capital letters\n",
    "    col = col.lower() # convert all characters to lower case\n",
    "    return col\n",
    "\n",
    "# dictionary of the columns to rename\n",
    "new_names = {'yearOfRegistration' : 'registration_year',\n",
    "             'monthOfRegistration' : 'registration_month',\n",
    "             'notRepairedDamage': 'unrepaired_damage',\n",
    "             'dateCreated' : 'ad_created',\n",
    "             'powerPS': 'power_ps'}\n",
    "\n",
    "# create new list for the new column names\n",
    "new_columns = []\n",
    "\n",
    "# modify the columns to have more suitable variable names\n",
    "for column in autos.columns:\n",
    "    if (column in [\"yearOfRegistration\", \"monthOfRegistration\", \"notRepairedDamage\", \"dateCreated\",\"powerPS\"]):\n",
    "        column = new_names[column]       \n",
    "    new_columns.append(clean_column(column))\n",
    "    \n",
    "# assign new columns as the datasets columns\n",
    "autos.columns = new_columns\n",
    "    \n",
    "# display new cleansed columns\n",
    "print(autos.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> Now, we can see that the new columns are all in snakecase, cleaned and still retains the intent of its use giving in the data dictionary. Also, we also decided to changed the 'powerPS' column seperately like the previous four columns we wanted to change, because the 'PS' part of it should be together, but out 'clean_column' function would of put underscores before each capital letter. Here, we have clear and understandable columns that we can use for our analysis which abides by the usual conventions of what we see in Python, such as the use of snakecase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Exploration</h2>\n",
    "<p>Now, let's explore the dataset deeper and focus on the actual data to see which areas need some cleaning up.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               date_crawled         name  seller offer_type  price abtest  \\\n",
      "count                 50000        50000   50000      50000  50000  50000   \n",
      "unique                48213        38754       2          2   2357      2   \n",
      "top     2016-03-22 09:51:06  Ford_Fiesta  privat    Angebot     $0   test   \n",
      "freq                      3           78   49999      49999   1421  25756   \n",
      "mean                    NaN          NaN     NaN        NaN    NaN    NaN   \n",
      "std                     NaN          NaN     NaN        NaN    NaN    NaN   \n",
      "min                     NaN          NaN     NaN        NaN    NaN    NaN   \n",
      "25%                     NaN          NaN     NaN        NaN    NaN    NaN   \n",
      "50%                     NaN          NaN     NaN        NaN    NaN    NaN   \n",
      "75%                     NaN          NaN     NaN        NaN    NaN    NaN   \n",
      "max                     NaN          NaN     NaN        NaN    NaN    NaN   \n",
      "\n",
      "       vehicle_type  registration_year  gearbox      power_ps  model  \\\n",
      "count         44905       50000.000000    47320  50000.000000  47242   \n",
      "unique            8                NaN        2           NaN    245   \n",
      "top       limousine                NaN  manuell           NaN   golf   \n",
      "freq          12859                NaN    36993           NaN   4024   \n",
      "mean            NaN        2005.073280      NaN    116.355920    NaN   \n",
      "std             NaN         105.712813      NaN    209.216627    NaN   \n",
      "min             NaN        1000.000000      NaN      0.000000    NaN   \n",
      "25%             NaN        1999.000000      NaN     70.000000    NaN   \n",
      "50%             NaN        2003.000000      NaN    105.000000    NaN   \n",
      "75%             NaN        2008.000000      NaN    150.000000    NaN   \n",
      "max             NaN        9999.000000      NaN  17700.000000    NaN   \n",
      "\n",
      "         odometer  registration_month fuel_type       brand unrepaired_damage  \\\n",
      "count       50000        50000.000000     45518       50000             40171   \n",
      "unique         13                 NaN         7          40                 2   \n",
      "top     150,000km                 NaN    benzin  volkswagen              nein   \n",
      "freq        32424                 NaN     30107       10687             35232   \n",
      "mean          NaN            5.723360       NaN         NaN               NaN   \n",
      "std           NaN            3.711984       NaN         NaN               NaN   \n",
      "min           NaN            0.000000       NaN         NaN               NaN   \n",
      "25%           NaN            3.000000       NaN         NaN               NaN   \n",
      "50%           NaN            6.000000       NaN         NaN               NaN   \n",
      "75%           NaN            9.000000       NaN         NaN               NaN   \n",
      "max           NaN           12.000000       NaN         NaN               NaN   \n",
      "\n",
      "                 ad_created  nr_of_pictures   postal_code            last_seen  \n",
      "count                 50000         50000.0  50000.000000                50000  \n",
      "unique                   76             NaN           NaN                39481  \n",
      "top     2016-04-03 00:00:00             NaN           NaN  2016-04-07 06:17:27  \n",
      "freq                   1946             NaN           NaN                    8  \n",
      "mean                    NaN             0.0  50813.627300                  NaN  \n",
      "std                     NaN             0.0  25779.747957                  NaN  \n",
      "min                     NaN             0.0   1067.000000                  NaN  \n",
      "25%                     NaN             0.0  30451.000000                  NaN  \n",
      "50%                     NaN             0.0  49577.000000                  NaN  \n",
      "75%                     NaN             0.0  71540.000000                  NaN  \n",
      "max                     NaN             0.0  99998.000000                  NaN  \n"
     ]
    }
   ],
   "source": [
    "# display descriptive statistics for all columns\n",
    "print(autos.describe(include = \"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> Here, we have a non informative column that is 'nr_of_pictures' as according to the data dictionary it was the number of photos in the ad but it seemed that this was not scrapped properly so all values are 0. This is evident above as we see the descriptive statistics for the column is all 0. Also, as we discussed before, we had to convert the 'price' and 'odometer' columns to numeric as they are currently objects or strings specifically. Furthermore, it seems that the columns 'seller' and 'offer_type' each have basically one re occuring value ('privat' and 'Angebot') in almost all of the rows (occurs 49999 times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date_crawled', 'name', 'seller', 'offer_type', 'price', 'abtest',\n",
      "       'vehicle_type', 'registration_year', 'gearbox', 'power_ps', 'model',\n",
      "       'odometer', 'registration_month', 'fuel_type', 'brand',\n",
      "       'unrepaired_damage', 'ad_created', 'postal_code', 'last_seen'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# remove the nr_of_pictures column\n",
    "autos = autos.drop(\"nr_of_pictures\", axis = 1)\n",
    "\n",
    "# display the remaining columns\n",
    "print(autos.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5000\n",
      "1    8500\n",
      "2    8990\n",
      "Name: price, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# convert the 'price' column into numeric\n",
    "price_col = autos[\"price\"]\n",
    "price_col = price_col.str.replace(\"[$,]\",\"\") # remove the $ and , from the price\n",
    "autos[\"price\"] = price_col.astype(int) # convert column to numeric and use new clean column\n",
    "print(autos[\"price\"].head(3)) # display the first 3 rows to show our conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    150000\n",
      "1    150000\n",
      "2     70000\n",
      "Name: odometer_km, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# convert the 'odometer' column into numeric\n",
    "odometer = autos[\"odometer\"]\n",
    "odometer = odometer.str.replace(\"km\", \"\") # remove the km at the end of each value\n",
    "odometer = odometer.str.replace(\",\", \"\") # remove the comma\n",
    "autos[\"odometer\"] = odometer.astype(int) # replace the current column with the new numeric column of values\n",
    "autos.rename({\"odometer\" : \"odometer_km\"}, axis = 1, inplace = True) # rename the column to a more suitable name\n",
    "print(autos[\"odometer_km\"].head(3)) # display the first 3 rows to show the final result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found some more problems within our dataset, we should explore further for disrepancies within our data and since we have converted the two above columns ('price' and 'odometer_km') to numeric, let's focus on analysing those newly converted columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Price ($): 0\n",
      "Maximum Price ($): 99999999\n"
     ]
    }
   ],
   "source": [
    "# get the min and max values of the price column\n",
    "min_price = autos[\"price\"].min()\n",
    "max_price = autos[\"price\"].max()\n",
    "print(\"Minimum Price ($):\", min_price)\n",
    "print(\"Maximum Price ($):\", max_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> It seems that we have a huge range between \\$0 to \\$99999999 of the listed used car prices, so we much check why the prices are so high that they are in the tens of millions range. I guess it is normal for prices to be $0 for used cars as some owners may like to disposed of their vehicles as they may have no value attached to them (i.e. not servicable or operational)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39705]\n"
     ]
    }
   ],
   "source": [
    "# display the indexes that have the max price\n",
    "print(autos.loc[autos.loc[:,\"price\"] == 99999999, :].index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> So, we see that the 39705th row contains this high priced car and we may assume that it was an error and since it is the only high value then it must be an outlier so we can remove the row entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 highest used car prices in the listings:\n",
      "39705    99999999\n",
      "42221    27322222\n",
      "27371    12345678\n",
      "39377    12345678\n",
      "47598    12345678\n",
      "2897     11111111\n",
      "24384    11111111\n",
      "11137    10000000\n",
      "47634     3890000\n",
      "7814      1300000\n",
      "Name: price, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# display the top 10 car prices in the listings\n",
    "print(\"Top 10 highest used car prices in the listings:\")\n",
    "print(autos[\"price\"].nlargest(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> Now, after further checking of the top 10 prices of the used cars, we see that the next few prices are also a bit steep im my opinion. So, it would be wise to use a more considerable price range and the next reasonable price that looks good would be the price of \\$3,890,000 (9th highest price) as anything above that maybe an accidental price being listed or the poster set the price a bit steep as to not sell the car at all. Thus, we should remove the other cars that are higher than our new max price ($3,890,000) and that should be our new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Minimum Price ($): 0\n",
      "New Maximum Price ($): 3890000\n",
      "(49992, 19)\n"
     ]
    }
   ],
   "source": [
    "# remove rows that are higher than the new price range\n",
    "min_range = 0\n",
    "max_range = 3890000\n",
    "autos = autos[autos[\"price\"].between(min_range, max_range)]\n",
    "\n",
    "# get the min and max values of the new price column\n",
    "min_price = autos[\"price\"].min()\n",
    "max_price = autos[\"price\"].max()\n",
    "print(\"New Minimum Price ($):\", min_price)\n",
    "print(\"New Maximum Price ($):\", max_price)\n",
    "\n",
    "# check how many rows of data remaining\n",
    "print(autos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> Here, we now have a new maximum price of $3,890,000 and after getting the dimensions of our new dataframe, we see that there is 49992 rows of data left out of our initialy 50000 rows (i.e. 8 rows were deleted in this process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     49992.000000\n",
      "mean     125734.017443\n",
      "std       40041.246220\n",
      "min        5000.000000\n",
      "25%      125000.000000\n",
      "50%      150000.000000\n",
      "75%      150000.000000\n",
      "max      150000.000000\n",
      "Name: odometer_km, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# display descriptive statistics regarding the odometer column\n",
    "print(autos[\"odometer_km\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> In the odometer column, the descriptive statistics look ok for the values that it has (measures the kilometers driven by the car) and we see that the minimum and maximum range is reasonable (5000, 150000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000        967\n",
      "10000       264\n",
      "20000       784\n",
      "30000       789\n",
      "40000       818\n",
      "50000      1026\n",
      "60000      1164\n",
      "70000      1230\n",
      "80000      1436\n",
      "90000      1757\n",
      "100000     2168\n",
      "125000     5170\n",
      "150000    32419\n",
      "Name: odometer_km, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# display the frequency of each value in the odometer column\n",
    "print(autos[\"odometer_km\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> The frequency of the kilometers driven by the used cars seem to fall within a handful of values given above. Here, we see that a majority of the used cars has been driven for at least 150,000 kilometers (32419 cars) and it seems there is no non numeric value for any of the rows. So based on this, we can conclude that there is no further fixing required for the 'odometer_km' column.\n",
    "\n",
    "<p>Now, that we have check the newly converted columns for any disrepancies and cleanse them, we should focus on the columns that contains dates to understand the times that these listings were made. Here, we have two categories of dates and they are either created by the web scraper to fetch these classifies data or dates that were from the actual page were the used car was listed (i.e. the seller's post date). From the data dictionary, we can find and seperate these columns into two categories, 'Crawler Dates' and 'Website Dates':</p>\n",
    "\n",
    "Crawler Dates (Columns):\n",
    "- 'date_crawled'\n",
    "- 'last_seen'\n",
    "\n",
    "Website Dates (Columns):\n",
    "- 'ad_created'\n",
    "- 'registration_month'\n",
    "- 'registration_year'\n",
    "\n",
    "Now, that we have all the date columns seperated, lets see what type of data they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_crawled          object\n",
      "last_seen             object\n",
      "ad_created            object\n",
      "registration_month     int64\n",
      "registration_year      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# check the datatypes of the dataset\n",
    "print(autos[['date_crawled', 'last_seen', 'ad_created', 'registration_month', 'registration_year']].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> So, there is 3 columns that are still object types and the other 2 are integer types, which are suitable for the column values they represent. Thus, we have to convert the first 3 columns into more suitable datatypes and we have examine a few rows to check their current format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date_crawled            last_seen           ad_created\n",
      "0  2016-03-26 17:47:46  2016-04-06 06:45:54  2016-03-26 00:00:00\n",
      "1  2016-04-04 13:38:56  2016-04-06 14:45:08  2016-04-04 00:00:00\n",
      "2  2016-03-26 18:57:24  2016-04-06 20:15:37  2016-03-26 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# display 3 rows of data regarding the columns date_crawled, last_seen and ad_created\n",
    "print(autos[[\"date_crawled\", \"last_seen\", \"ad_created\"]].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> It seems that there is a consistent format that the 3 columns use and it is the datetime format in Python. The format starts with the date starting from the year down to the day  and then it is followed by the timestamp of the car listing.\n",
    "\n",
    "We should focus on the website data more than the crawlers data as we want to analyze the eBay listings rather than the web scraper itself and that means we should get the frequency of the listings for each ad in terms of their post date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-06-11    0.000020\n",
      "2015-08-10    0.000020\n",
      "2015-09-09    0.000020\n",
      "2015-11-10    0.000020\n",
      "2015-12-05    0.000020\n",
      "2015-12-30    0.000020\n",
      "2016-01-03    0.000020\n",
      "2016-01-07    0.000020\n",
      "2016-01-10    0.000040\n",
      "2016-01-13    0.000020\n",
      "2016-01-14    0.000020\n",
      "2016-01-16    0.000020\n",
      "2016-01-22    0.000020\n",
      "2016-01-27    0.000060\n",
      "2016-01-29    0.000020\n",
      "2016-02-01    0.000020\n",
      "2016-02-02    0.000040\n",
      "2016-02-05    0.000040\n",
      "2016-02-07    0.000020\n",
      "2016-02-08    0.000020\n",
      "2016-02-09    0.000040\n",
      "2016-02-11    0.000020\n",
      "2016-02-12    0.000060\n",
      "2016-02-14    0.000040\n",
      "2016-02-16    0.000020\n",
      "2016-02-17    0.000020\n",
      "2016-02-18    0.000040\n",
      "2016-02-19    0.000060\n",
      "2016-02-20    0.000040\n",
      "2016-02-21    0.000060\n",
      "                ...   \n",
      "2016-03-09    0.033225\n",
      "2016-03-10    0.031865\n",
      "2016-03-11    0.032785\n",
      "2016-03-12    0.036606\n",
      "2016-03-13    0.016923\n",
      "2016-03-14    0.035226\n",
      "2016-03-15    0.033745\n",
      "2016-03-16    0.030005\n",
      "2016-03-17    0.031205\n",
      "2016-03-18    0.013722\n",
      "2016-03-19    0.033845\n",
      "2016-03-20    0.037866\n",
      "2016-03-21    0.037706\n",
      "2016-03-22    0.032785\n",
      "2016-03-23    0.032185\n",
      "2016-03-24    0.029085\n",
      "2016-03-25    0.031885\n",
      "2016-03-26    0.032565\n",
      "2016-03-27    0.030905\n",
      "2016-03-28    0.034966\n",
      "2016-03-29    0.034125\n",
      "2016-03-30    0.033445\n",
      "2016-03-31    0.031905\n",
      "2016-04-01    0.033805\n",
      "2016-04-02    0.035086\n",
      "2016-04-03    0.038926\n",
      "2016-04-04    0.036886\n",
      "2016-04-05    0.011842\n",
      "2016-04-06    0.003261\n",
      "2016-04-07    0.001280\n",
      "Name: ad_created, Length: 76, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# display the distribution of dates of when the ad was created\n",
    "ad_dates = autos[\"ad_created\"].str[:10].value_counts(normalize = True, dropna = False)\n",
    "ad_dates = ad_dates.sort_index()\n",
    "print(ad_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> Here, we see that the highest percentage of listings for used cars were during the March and April months of 2016 as shown by the distribution above (second column given as %). \n",
    "\n",
    "Now, let's look at the other two columns that were also apart of the listings data, which were the 'registration_month' and 'registration_year'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registration Month:\n",
      "count    49992.000000\n",
      "mean         5.723796\n",
      "std          3.711938\n",
      "min          0.000000\n",
      "25%          3.000000\n",
      "50%          6.000000\n",
      "75%          9.000000\n",
      "max         12.000000\n",
      "Name: registration_month, dtype: float64\n",
      "\n",
      "Registration Year:\n",
      "count    49992.000000\n",
      "mean      2005.074552\n",
      "std        105.720930\n",
      "min       1000.000000\n",
      "25%       1999.000000\n",
      "50%       2003.000000\n",
      "75%       2008.000000\n",
      "max       9999.000000\n",
      "Name: registration_year, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# display the descriptive statistics for registration_month\n",
    "print(\"Registration Month:\")\n",
    "print(autos[\"registration_month\"].describe())\n",
    "\n",
    "# display the descriptive statistics for registration_year\n",
    "print(\"\\nRegistration Year:\")\n",
    "print(autos[\"registration_year\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> For the 'registration_month' column we see the minimum month in the dataset is 0, which obviously is not possible, but this may just be because the month posted maybe omitted and thus the value 0 is assigned. However, for the 'registration_year' column we see that the minimum year is 1000 and the maximum year is 9999, which is also impossible and those rows will need removal as well.\n",
    "\n",
    "Now, logic will imply that the registration year will surely be before the ad is posted, such that any registration year for a used car should not exceed the year that the ad is posted (in this dataset it is between 2015-2016). In this case, we must filter out rows of data that have the registration year for the car, exceeding the year the ad was posted, as this would be impossible in real life. Well, unless they can time travel then that would invoke more curiosity to those individuals that posted the ad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000       1\n",
      "1001       1\n",
      "1111       1\n",
      "1500       1\n",
      "1800       2\n",
      "1910       9\n",
      "1927       1\n",
      "1929       1\n",
      "1931       1\n",
      "1934       2\n",
      "1937       4\n",
      "1938       1\n",
      "1939       1\n",
      "1941       2\n",
      "1943       1\n",
      "1948       1\n",
      "1950       3\n",
      "1951       2\n",
      "1952       1\n",
      "1953       1\n",
      "1954       2\n",
      "1955       2\n",
      "1956       5\n",
      "1957       2\n",
      "1958       4\n",
      "1959       7\n",
      "1960      33\n",
      "1961       6\n",
      "1962       4\n",
      "1963       9\n",
      "        ... \n",
      "2001    2702\n",
      "2002    2533\n",
      "2003    2727\n",
      "2004    2737\n",
      "2005    3015\n",
      "2006    2708\n",
      "2007    2304\n",
      "2008    2231\n",
      "2009    2098\n",
      "2010    1597\n",
      "2011    1634\n",
      "2012    1323\n",
      "2013     806\n",
      "2014     665\n",
      "2015     399\n",
      "2016    1316\n",
      "2017    1452\n",
      "2018     491\n",
      "2019       3\n",
      "2800       1\n",
      "4100       1\n",
      "4500       1\n",
      "4800       1\n",
      "5000       4\n",
      "5911       1\n",
      "6200       1\n",
      "8888       1\n",
      "9000       2\n",
      "9996       1\n",
      "9999       4\n",
      "Name: registration_year, Length: 97, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# display the frequency of the registration years for the used cars\n",
    "print(autos[\"registration_year\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> It, is clear there is some outlandish registration years for cars that make absolutely no sense. So, it would be wise to remove any years that exceed the year 2016 and any cars that were registered before 1910, to make the data more valid and to hide any time-travelling car enthusiast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1910    0.000187\n",
      "1927    0.000021\n",
      "1929    0.000021\n",
      "1931    0.000021\n",
      "1934    0.000042\n",
      "1937    0.000083\n",
      "1938    0.000021\n",
      "1939    0.000021\n",
      "1941    0.000042\n",
      "1943    0.000021\n",
      "1948    0.000021\n",
      "1950    0.000062\n",
      "1951    0.000042\n",
      "1952    0.000021\n",
      "1953    0.000021\n",
      "1954    0.000042\n",
      "1955    0.000042\n",
      "1956    0.000104\n",
      "1957    0.000042\n",
      "1958    0.000083\n",
      "1959    0.000146\n",
      "1960    0.000687\n",
      "1961    0.000125\n",
      "1962    0.000083\n",
      "1963    0.000187\n",
      "1964    0.000250\n",
      "1965    0.000354\n",
      "1966    0.000458\n",
      "1967    0.000562\n",
      "1968    0.000541\n",
      "          ...   \n",
      "1987    0.001562\n",
      "1988    0.002957\n",
      "1989    0.003769\n",
      "1990    0.008225\n",
      "1991    0.007413\n",
      "1992    0.008142\n",
      "1993    0.009267\n",
      "1994    0.013744\n",
      "1995    0.027321\n",
      "1996    0.030070\n",
      "1997    0.042231\n",
      "1998    0.051081\n",
      "1999    0.062451\n",
      "2000    0.069843\n",
      "2001    0.056266\n",
      "2002    0.052747\n",
      "2003    0.056786\n",
      "2004    0.056995\n",
      "2005    0.062784\n",
      "2006    0.056391\n",
      "2007    0.047978\n",
      "2008    0.046458\n",
      "2009    0.043688\n",
      "2010    0.033256\n",
      "2011    0.034026\n",
      "2012    0.027550\n",
      "2013    0.016784\n",
      "2014    0.013848\n",
      "2015    0.008309\n",
      "2016    0.027404\n",
      "Name: registration_year, Length: 78, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# filter out rows that exceed or go under certain registration years\n",
    "min_rego_year = 1910\n",
    "max_rego_year = 2016\n",
    "autos = autos[autos[\"registration_year\"].between(min_rego_year, max_rego_year)]\n",
    "\n",
    "# recheck the registration range again\n",
    "print(autos[\"registration_year\"].value_counts(normalize = True).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> We have now filtered out more rows of data and so the range of registration years on cars seem more reasonable. In terms of the distribution, it looks like that the registration years for cars are more skewed towards the modern era (1987-2016) and that may imply that the used cars listed for sale are within the past 30 years, in terms of their age.\n",
    "\n",
    "Now, that we have cleaned a considerable amount of the dataset and filtered out the non sensical rows, let's look at the main attraction which is the brand of used cars. We can display the top 10 brand of used cars on sale and also the average price for each brand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 car brands in the eBay listings and their frequencies:\n",
      "volkswagen       10187\n",
      "bmw               5284\n",
      "opel              5194\n",
      "mercedes_benz     4579\n",
      "audi              4149\n",
      "ford              3351\n",
      "renault           2274\n",
      "peugeot           1418\n",
      "fiat              1242\n",
      "seat               873\n",
      "Name: brand, dtype: int64\n",
      "\n",
      "Average prices for top 10 car brands:\n",
      "Car Brand: volkswagen | Average Price: $5426.38\n",
      "Car Brand: bmw | Average Price: $8334.65\n",
      "Car Brand: opel | Average Price: $2876.72\n",
      "Car Brand: mercedes_benz | Average Price: $8485.24\n",
      "Car Brand: audi | Average Price: $9093.65\n",
      "Car Brand: ford | Average Price: $3949.42\n",
      "Car Brand: renault | Average Price: $2395.42\n",
      "Car Brand: peugeot | Average Price: $3039.47\n",
      "Car Brand: fiat | Average Price: $2711.80\n",
      "Car Brand: seat | Average Price: $4296.49\n"
     ]
    }
   ],
   "source": [
    "# fetch the brand of cars\n",
    "brands = autos[\"brand\"]\n",
    "\n",
    "# display the frequency of the cars (top 10)\n",
    "print(\"Top 10 car brands in the eBay listings and their frequencies:\")\n",
    "top_brands = brands.value_counts().nlargest(10)\n",
    "print(top_brands)\n",
    "\n",
    "# dictionary to store the aggregate of the top 10 car brand prices\n",
    "brand_mean_prices = {}\n",
    "for brand in top_brands.index:\n",
    "    brand_df = autos.loc[autos.loc[:,\"brand\"] == brand, :]\n",
    "    total_price = brand_df[\"price\"].sum()\n",
    "    mean_price = total_price/top_brands[brand]\n",
    "    brand_mean_prices[brand] = mean_price\n",
    "\n",
    "# display the mean sale prices of top 10 car brands\n",
    "print(\"\\nAverage prices for top 10 car brands:\")\n",
    "for brand in top_brands.index:\n",
    "    template = \"Car Brand: {brand} | Average Price: ${mean_price:0.2f}\"\n",
    "    print(template.format(brand = brand, mean_price = brand_mean_prices[brand]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> So, it looks like that the average price of these top 10 car brands is under \\$10000, with the lowest being Renault brand (\\$2395.42) and the highest belonging to the Audi brand (\\$9093.65).\n",
    "\n",
    "Now, we should get the average mileage of these car brands and see if there is any connection between the average price and mileage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              average_price average_mileage\n",
      "audi               $9093.65     129287.78km\n",
      "bmw                $8334.65     132434.71km\n",
      "fiat                $2711.8     116553.95km\n",
      "ford               $3949.42     124068.93km\n",
      "mercedes_benz      $8485.24     130856.08km\n",
      "opel               $2876.72     129223.14km\n",
      "peugeot            $3039.47     127136.81km\n",
      "renault            $2395.42     128183.82km\n",
      "seat               $4296.49     121563.57km\n",
      "volkswagen         $5426.38     128728.28km\n"
     ]
    }
   ],
   "source": [
    "# get the average mileage for each car brand\n",
    "avg_mileage = {}\n",
    "for brand in top_brands.index:\n",
    "    brand_mileage = autos.loc[autos.loc[:,\"brand\"] == brand, :]\n",
    "    brand_mileage = brand_mileage[\"odometer_km\"].sum()\n",
    "    average_mileage = brand_mileage/top_brands[brand]\n",
    "    avg_mileage[brand] = average_mileage\n",
    "    \n",
    "# merge both average price and mileage into a single dataframe from the dictionaries\n",
    "df = \"$\" + pd.Series(brand_mean_prices).round(2).astype(str)\n",
    "df = pd.DataFrame(df, columns = [\"average_price\"])\n",
    "df[\"average_mileage\"] = pd.Series(avg_mileage).round(2).astype(str) + \"km\"\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> Here, there does not seem to be a big correlation between the average price of brands of used cars and their mileage. As we can seem, the average mileage of all the top 10 car brads in this dataset, seem to exceed 100,000 km which means all the cars have high usage before they were put on sale. Also, regardless of the price, the distribution of the mileage seem to be about the same despite the big average price differences between the most expensive car brand (Audi) and least expensive (Renault)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
